<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>나의 블로그</title>
    <link>https://chiwoo.bmdevs.com/</link>
    <description>Recent content on 나의 블로그</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ko-kr</language>
    <lastBuildDate>Fri, 02 Apr 2021 23:31:08 +0900</lastBuildDate><atom:link href="https://chiwoo.bmdevs.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>클라우드 VM의 Scale Out</title>
      <link>https://chiwoo.bmdevs.com/post/cloud/scale-out/</link>
      <pubDate>Fri, 02 Apr 2021 23:31:08 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/cloud/scale-out/</guid>
      <description>클라우드 환경에서 Scale Out 다양한 클라우드 벤더에선 클라우드의 장점중 하나인 빠른 딜리버리를 사용하여 자동 확장 VM 서비스를 제공하고 있다. 그리고 구성 방법도 매우 심플하여 쉽게 사용할 수 있을 것 같지만 고려해야 할 사항이 몇 가지 존재한다.
1. 버전 관리  Scale Out VM은 빠른 배포를 목적으로 하기 때문에 미리 구성된 가상머신 이미지를 참조하여 수평 확장을 진행한다. 그렇기 때문에 이미 애플리케이션이 모두 탑재된 이미지를 만들어 두거나, OS가 설치되어있고 기본적인 보안 구성이 완료된 이미지로 VM을 만들도록 한 후, 시작 스크립트로 모든 애플리케이션을 작동시키도록 해야한다.</description>
    </item>
    
    <item>
      <title>Azure 리소스 모니터링 서버 만들기 (3)</title>
      <link>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv3/</link>
      <pubDate>Mon, 04 Jan 2021 22:12:20 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv3/</guid>
      <description>가상머신 CPU 대시보드 만들기  앞서 포스트에선 Grafana 설치와 Azure 플러그인을 사용하여 데이터소스를 연결하는 방법을 알아보았습니다. 이번 포스트에선 Azure VM을 모니터링하는 간단한 대시보드를 만들어 보겠습니다. 그리고 Azure Plugin 에서 사용할 수 있는 빌트인 변수와, 그 변수를 사용하여 동적으로 메트릭이 추가되는 패널을 만들어보도록 하겠습니다. 대시보드 추가  먼저 좌측메뉴에서 Create - Dashboard를 선택하여 대시보드를 만듭니다.
  아래 순서대로 현재 대시보드의 이름을 지정하고 저장합니다.
  다음으로 데이터를 표현할 패널을 만듭니다. 패널은 메트릭 뿐만 아니라 로그, 테이블 등 다양한 데이터를 표현할 수 있습니다.</description>
    </item>
    
    <item>
      <title>Azure 리소스 모니터링 서버 만들기 (2)</title>
      <link>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv2/</link>
      <pubDate>Wed, 09 Dec 2020 20:46:49 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv2/</guid>
      <description>모니터링 환경 구성하기  앞서 포스트에선 Grafana와 Azure Monitor 기능을 이용하여 Azure 리소스를 모니터링 할 때의 장/단점과 특징들을 살펴보았습니다. 이번 포스트 부터 Grafana 모니터링 시스템을 구축하도록 하겠습니다.
Azure AD App 만들기  우선 사용자를 대신하여 백그라운드에서 Azure API의 인증과 권한을 획득하여 Metric API의 데이터를 읽어올 수 있는 Azure AD App을 추가합니다. Azure AD App은 Azure AD의 앱등록 에서 만들 수 있습니다. Azure AD App을 만들기 전에 아래 사진과 같이 사용자 계정이 Azure AD 내에서 애플리케이션 개발자 이상의 역할을 가지고 있어야 합니다.</description>
    </item>
    
    <item>
      <title>Azure 리소스 모니터링 서버 만들기 (1)</title>
      <link>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv1/</link>
      <pubDate>Tue, 24 Nov 2020 21:29:55 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/grafana/made_grafana-srv1/</guid>
      <description>Azure 기본 모니터  Azure 모니터는 Azure 뿐만 아니라 On-premise, 다른 클라우드 환경의 모니터링 데이터를 수집, 분석할 수 있으며 여러가지 알림을 보낼 수 있습니다. Azure에서 VM을 만들 경우 아래 그림처럼 VM의 모니터링 블레이드에서 기본적으로 CPU, 디스크, 네트워크 메트릭을 확인할 수 있습니다.   아쉽게도 메모리를 확인하려면 OMS Agent 혹은 VM Guest 에이전트를 설치해야 합니다.
모니터링 대시보드를 만드는 과정은 약간 처참하지만, 시간을 들이면 아래와 같은 화면을 만들 수도 있습니다.
  위의 대시보드는 Azure의 Workbooks 기능으로 Azure Metric API가 제공하는 데이터를 사용하여 만들어집니다.</description>
    </item>
    
    <item>
      <title>AKS RBAC 과 Azure AD 통합</title>
      <link>https://chiwoo.bmdevs.com/post/kubernetes-aks-aad/</link>
      <pubDate>Fri, 04 Sep 2020 16:33:25 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/kubernetes-aks-aad/</guid>
      <description>AAD와 AKS의 RBAC Kubernetes 클러스터 보안을 위해 Kubernetes 리소스를 컨트롤 할 수 있는 사용자를 제한할 수 있다. 예를 들어 클러스터 관리자를 한 명 선정하고 그 관리자 에게만 포드, 서비스등 리소스를 배포할 수 있는 권한을 부여할 수 있다. AKS를 사용하면 손쉽게 Azure AD의 원하는 사용자, 그룹에게 해당 작업을 수행할 수 있다.
이를 위해선 클러스터의 RBAC 플러그인을 활성화하고, AKS관리형 Azure AD 기능이 &amp;ldquo;사용&amp;rdquo; 상태로 배포됐어야한다.   　기본    Kubernetes는 사용자 정보를 클러스터 내부에 저장하지 않는다.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://chiwoo.bmdevs.com/about/about/</link>
      <pubDate>Thu, 03 Sep 2020 13:10:29 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/about/about/</guid>
      <description>소개 페이지 작성 dzez</description>
    </item>
    
    <item>
      <title>Kubernetes Daemonset</title>
      <link>https://chiwoo.bmdevs.com/post/kubernetes-daemonset/</link>
      <pubDate>Thu, 03 Sep 2020 11:06:22 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/kubernetes-daemonset/</guid>
      <description>Daemonset, 데몬셋 레플리카셋은 Kubernetes 클러스터의 특정 위치에 배포된 특정 개수의 포드를 실행하는 데 사용된다. 그러나 노드 로그 수집기, 노드 리소스 모니터 수집기 등 각 노드에서 정확히 하나의 포드를 실행해야 하는 경우가 있다. 이 경우 데몬셋을 사용한다.
기본  데몬셋에 의해 만들어진 포드는 이미 대상 노드가 지정돼 욌고 Kubernetes 스케줄러를 패스한다. 데몬셋은 레플리카의 개념이 없고 노드가 있는 수만큼 포드를 생성하고 노드 각각에 포드를 하나씩 배포한다. 노드가 다운되면 데몬셋은 다운된 노드의 포드를 다른 노드로 스케줄하지 않는다.</description>
    </item>
    
    <item>
      <title>Kubernetes Replicaset</title>
      <link>https://chiwoo.bmdevs.com/post/kubernetes-replicaset/</link>
      <pubDate>Wed, 02 Sep 2020 15:50:46 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/kubernetes-replicaset/</guid>
      <description>Replicaset, 레플리카셋 레플리카셋은 포드의 복제본을 일정한 수의 복제본으로 유지하려고 노력하는 Kubernetes 리소스다. 최초에는 레플리케이션 컨트롤러가 포드를 복제하고 노드가 실패했을 때 재스키줄링하는 유일한 Kubernetes 구성 요소였다. 나중에 레플리케이션 컨트롤러보다 더 진보된 레플리카셋이라는 리소스가 도입됐다.
기본  레플리카셋은 레플리케이션컨트롤러와 똑같이 동작하지만 다양한 포드 셀렉터를 갖는다. 레플리케이션 컨트롤러는 단일 셀렉터만 사용해 포드를 매칭시켰지만, 레플리카셋은 특정 라벨이 있거나 없거나와 여러개의 라벨을 일치시킬 수 있다. 또한 env=*과 같이, 특정 라벨 키를 가진 모든 포드를 매칭시킬 수도 있다.</description>
    </item>
    
    <item>
      <title>Kubernetes Pod</title>
      <link>https://chiwoo.bmdevs.com/post/kubernetes-pod1/</link>
      <pubDate>Tue, 01 Sep 2020 15:56:21 +0900</pubDate>
      
      <guid>https://chiwoo.bmdevs.com/post/kubernetes-pod1/</guid>
      <description>Pod, 포드 Pod는 Kubernetes 애플리케이션의 배포 단위이다. Pod 안에는 여러 컨테이너를 배치할 수 있으며 같은 Pod는 같은 네임스페이스를 공유하기 때문에 hostname, ip등을 공유하게 된다.
기본  포드는 컨테이너의 공동의 배치 그룹이며 Kubernetes의 기본 빌딩 블록을 대표한다. Kubernetes는 컨테이너를 개별적으로 배포하는 대신 항상 컨테이너의 포드를 배포하고 운영한다. 포드는 일반적으로 단일 컨테이너를 포함하지만 여러 개의 컨테이너를 포함하여 배포할 수 있다. 같은 포드 내의 컨테이너는 동일한 워커노드에서 실행된다. 포드에는 볼륨이라는 저장소를 마운트하여 포드 내의 컨테이너가 볼륨을 공유하며 사용할 수 있다.</description>
    </item>
    
  </channel>
</rss>
